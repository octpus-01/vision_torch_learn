

ä»¥ä¸‹æ˜¯é’ˆå¯¹ CIFAR-10 åˆ†ç±»ä»»åŠ¡çš„**å…³é”®ä»£ç æŒ‡å—**ï¼Œä¸“æ³¨äº**æ¡†æ¶åŸºç¡€æ“ä½œ**ã€‚æˆ‘å°†æä¾›**æ ¸å¿ƒä»£ç ç‰‡æ®µ**å’Œ**è¯¦ç»†æŒ‡å¯¼**ï¼Œå¸®åŠ©ä½ ç†è§£ PyTorch å’Œ TensorBoard çš„å·¥ä½œæµç¨‹ï¼Œ**ä¸æä¾›å®Œæ•´ä»£ç **ï¼Œè€Œæ˜¯æ•™ä½ å¦‚ä½•æ„å»ºè‡ªå·±çš„ä»£ç ã€‚

---

### ğŸ“Œ æ ¸å¿ƒç›®æ ‡
1. åŠ è½½ CIFAR-10 æ•°æ®é›†ï¼ˆå·²å­˜æ”¾åœ¨ `data/cifar10`ï¼‰
2. å®ç° 3 ç§ä¸åŒæ¨¡å‹ï¼ˆç®€å• CNN / ResNet18 / VGG11ï¼‰
3. ç”¨ TensorBoard å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹
4. æŒæ¡ PyTorch è§†è§‰ä»»åŠ¡åŸºç¡€æ“ä½œ

---

## ğŸ”§ å…³é”®ä»£ç éƒ¨åˆ†ä¸ç¼–å†™æŒ‡å—

### âœ… 1. æ•°æ®åŠ è½½ï¼ˆæ ¸å¿ƒï¼š`torchvision.datasets`ï¼‰
**ä¸ºä»€ä¹ˆé‡è¦**ï¼šCIFAR-10 æ˜¯æ ‡å‡†è§†è§‰æ•°æ®é›†ï¼Œæ•°æ®åŠ è½½æ˜¯ç¬¬ä¸€æ­¥ã€‚

```python
import torchvision
import torchvision.transforms as transforms

# 1. å®šä¹‰æ•°æ®è½¬æ¢ï¼ˆå…³é”®ï¼ï¼‰
transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),  # æ•°æ®å¢å¼º
    transforms.RandomHorizontalFlip(),     # éšæœºç¿»è½¬
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))  # æ ‡å‡†åŒ–
])

# 2. åŠ è½½æ•°æ®é›†ï¼ˆæ³¨æ„ root è·¯å¾„ï¼ï¼‰
trainset = torchvision.datasets.CIFAR10(
    root='train/cifar10',  # ä½ çš„æ•°æ®ç›®å½•
    train=True,
    download=False,       # å·²å­˜åœ¨ï¼Œä¸ä¸‹è½½
    transform=transform
)

testset = torchvision.datasets.CIFAR10(
    root='train/cifar10',
    train=False,
    download=False,
    transform=transform
)

# 3. åˆ›å»º DataLoaderï¼ˆå…³é”®ï¼šbatch_size å’Œ shuffleï¼‰
trainloader = torch.utils.data.DataLoader(
    trainset,
    batch_size=128,       # å¸¸ç”¨å€¼
    shuffle=True,         # æ‰“ä¹±æ•°æ®
    num_workers=2         # å¤šè¿›ç¨‹åŠ è½½
)
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `transforms` æ˜¯**æ•°æ®é¢„å¤„ç†æ ¸å¿ƒ**ï¼Œå¿…é¡»åšæ ‡å‡†åŒ–
- `root` è·¯å¾„å¿…é¡»æŒ‡å‘ä½ å­˜æ”¾æ•°æ®çš„ç›®å½•
- `download=False` **å¿…é¡»**ï¼Œå› ä¸ºæ•°æ®å·²å­˜åœ¨
- `num_workers` æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´ï¼ˆ2-4ï¼‰

---

### âœ… 2. æ¨¡å‹æ–¹æ¡ˆï¼ˆ3 ç§é€‰æ‹©ï¼Œé€‰ä¸€ç§å³å¯ï¼‰
#### æ–¹æ¡ˆ A: ç®€å• CNNï¼ˆé€‚åˆå…¥é—¨ï¼‰
```python
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),  # 3é€šé“è¾“å…¥ï¼Œ32ä¸ªå·ç§¯æ ¸
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 8 * 8, 128),  # 64é€šé“ * 8x8ç‰¹å¾å›¾
            nn.ReLU(),
            nn.Linear(128, 10)            # 10ç±»è¾“å‡º
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        return self.classifier(x)
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- è¾“å…¥å°ºå¯¸ï¼š32Ã—32Ã—3 â†’ ç»è¿‡ä¸¤æ¬¡ MaxPool åå˜æˆ 8Ã—8Ã—64
- `nn.Conv2d` å‚æ•°ï¼š`(è¾“å…¥é€šé“, è¾“å‡ºé€šé“, å·ç§¯æ ¸å¤§å°)`
- `view(-1)` æ˜¯**å…³é”®æ“ä½œ**ï¼šå°†ç‰¹å¾å›¾å±•å¹³ä¸ºå‘é‡

---

#### æ–¹æ¡ˆ B: ResNet18ï¼ˆå·¥ä¸šçº§é€‰æ‹©ï¼‰
```python
# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä½†ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
model = torchvision.models.resnet18(pretrained=False)

# ä¿®æ”¹è¾“å…¥å±‚ï¼ˆCIFAR-10 æ˜¯ 32x32ï¼ŒåŸ ResNet ä¸º 224x224ï¼‰
model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)

# ä¿®æ”¹è¾“å‡ºå±‚ï¼ˆ10ç±»ï¼‰
model.fc = nn.Linear(model.fc.in_features, 10)
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `pretrained=False`ï¼šä¸åŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡ï¼ˆCIFAR-10 ç”¨ä¸åˆ°ï¼‰
- `model.conv1` ä¿®æ”¹ï¼šå› ä¸ºè¾“å…¥å°ºå¯¸å°ï¼Œæ­¥é•¿æ”¹ä¸º 1
- `model.fc` ä¿®æ”¹ï¼šè¾“å‡ºå±‚ä» 1000 ç±» â†’ 10 ç±»

---

#### æ–¹æ¡ˆ C: VGG11ï¼ˆç»å…¸é€‰æ‹©ï¼‰
```python
model = torchvision.models.vgg11(pretrained=False)
model.features[0] = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # ä¿®æ”¹è¾“å…¥å±‚
model.classifier[6] = nn.Linear(4096, 10)  # ä¿®æ”¹è¾“å‡ºå±‚
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `vgg11` çš„ `features` å’Œ `classifier` ç»“æ„å›ºå®š
- `features[0]` æ˜¯ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼ˆè¾“å…¥é€šé“æ”¹ä¸º 3ï¼‰
- `classifier[6]` æ˜¯æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆè¾“å‡º 10 ç±»ï¼‰

---

### âœ… 3. TensorBoard ç›‘æ§ï¼ˆæ ¸å¿ƒï¼š`SummaryWriter`ï¼‰
```python
from torch.utils.tensorboard import SummaryWriter

# 1. åˆå§‹åŒ– writerï¼ˆæ—¥å¿—ç›®å½•ï¼‰
writer = SummaryWriter(log_dir='runs/cifar10_resnet18')

# 2. åœ¨è®­ç»ƒå¾ªç¯ä¸­è®°å½•
for epoch in range(epochs):
    for batch_idx, (inputs, labels) in enumerate(trainloader):
        # ... å‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­ ...
        
        # è®°å½•è®­ç»ƒæŸå¤±
        writer.add_scalar('Loss/train', loss.item(), epoch * len(trainloader) + batch_idx)
        
        # è®°å½•å­¦ä¹ ç‡
        writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch * len(trainloader) + batch_idx)

    # æ¯ä¸ª epoch ç»“æŸï¼Œè®°å½•æµ‹è¯•å‡†ç¡®ç‡
    test_acc = evaluate(model, testloader)
    writer.add_scalar('Accuracy/test', test_acc, epoch)
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `log_dir`ï¼šæŒ‡å®š TensorBoard æ—¥å¿—è·¯å¾„
- `add_scalar`ï¼šè®°å½•æ ‡é‡æ•°æ®ï¼ˆlossã€accuracyã€lrï¼‰
- **å…³é”®ç‚¹**ï¼š`global_step` å‚æ•°æ˜¯**ç´¯è®¡æ­¥æ•°**ï¼ˆ`epoch * len(loader) + batch_idx`ï¼‰
- æµ‹è¯•å‡†ç¡®ç‡åœ¨**æ¯ä¸ª epoch ç»“æŸæ—¶**è®°å½•

---

### âœ… 4. è®­ç»ƒå¾ªç¯ï¼ˆå…³é”®ï¼šä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼‰
```python
# 1. é€‰æ‹©æ¨¡å‹ï¼ˆä¾‹å¦‚ ResNet18ï¼‰
model = model.to(device)  # ç§»åˆ° GPU

# 2. å®šä¹‰ä¼˜åŒ–å™¨ï¼ˆAdam é€‚åˆå›¾åƒä»»åŠ¡ï¼‰
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 3. å®šä¹‰æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()

# 4. è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒï¼‰
for epoch in range(epochs):
    model.train()
    for inputs, labels in trainloader:
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `device = torch.device("cuda" if torch.cuda.is_available() else "cpu")`ï¼š**å¿…é¡»**åˆ¤æ–­ GPU å¯ç”¨æ€§
- `optimizer.zero_grad()`ï¼š**æ¯æ¬¡è®­ç»ƒå‰å¿…é¡»æ¸…é›¶æ¢¯åº¦**
- `model.train()`ï¼š**è®­ç»ƒæ¨¡å¼**ï¼ˆå½±å“ BatchNorm/ Dropoutï¼‰
- `criterion = nn.CrossEntropyLoss()`ï¼š**åˆ†ç±»ä»»åŠ¡æ ‡å‡†æŸå¤±**

---

### âœ… 5. è¯„ä¼°å‡½æ•°ï¼ˆå…³é”®ï¼šå‡†ç¡®ç‡è®¡ç®—ï¼‰
```python
def evaluate(model, dataloader):
    model.eval()  # è¯„ä¼°æ¨¡å¼
    correct = 0
    total = 0
    with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total
```

**ğŸ“Œ æŒ‡å¯¼**ï¼š
- `model.eval()`ï¼š**å¿…é¡»**åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
- `torch.no_grad()`ï¼š**èŠ‚çœå†…å­˜**ï¼Œä¸è®¡ç®—æ¢¯åº¦
- `torch.max(outputs, 1)`ï¼šè·å–é¢„æµ‹ç±»åˆ«ï¼ˆæ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•ï¼‰

---

## ğŸš€ ä½ çš„å·¥ä½œæµç¨‹æŒ‡å—

1. **é€‰æ‹©ä¸€ç§æ¨¡å‹**ï¼ˆä» 3 ç§ä¸­é€‰ 1 ç§ï¼‰
2. **æŒ‰æŒ‡å¯¼å†™æ•°æ®åŠ è½½**ï¼ˆæ³¨æ„ `root` è·¯å¾„å’Œ `download=False`ï¼‰
3. **å®ç°è®­ç»ƒå¾ªç¯**ï¼ˆåŒ…å« `optimizer.zero_grad()` å’Œ `loss.backward()`ï¼‰
4. **åŠ å…¥ TensorBoard è®°å½•**ï¼ˆ`writer.add_scalar`ï¼‰
5. **å®ç°è¯„ä¼°å‡½æ•°**ï¼ˆè®¡ç®—å‡†ç¡®ç‡ï¼‰
6. **å¯åŠ¨ TensorBoard**ï¼š
   ```bash
   tensorboard --logdir=runs
   ```
   â†’ æ‰“å¼€æµè§ˆå™¨è®¿é—® `http://localhost:6006`

---

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

| æ“ä½œ | ä¸ºä»€ä¹ˆé‡è¦ | ä½ å­¦åˆ°çš„ |
|------|------------|----------|
| æ•°æ®å¢å¼º | æé«˜æ³›åŒ–èƒ½åŠ› | è§†è§‰ä»»åŠ¡å¿…å¤‡ |
| `view(-1)` | ç‰¹å¾å›¾å±•å¹³ | ç¥ç»ç½‘ç»œåŸºç¡€ |
| `optimizer.zero_grad()` | é˜²æ­¢æ¢¯åº¦ç´¯åŠ  | æ·±åº¦å­¦ä¹ å…³é”® |
| `model.train()`/`eval()` | æ¨¡å¼åˆ‡æ¢ | æ¨¡å‹æ­£ç¡®ä½¿ç”¨ |
| `torch.no_grad()` | èŠ‚çœå†…å­˜ | é«˜æ•ˆè®­ç»ƒ |

---

## âŒ å¸¸è§é”™è¯¯é¿å…

1. **æ•°æ®è·¯å¾„é”™è¯¯** â†’ æ£€æŸ¥ `root='train/cifar10'`
2. **å¿˜è®°æ ‡å‡†åŒ–** â†’ CIFAR-10 å¿…é¡»ç”¨ `(0.4914, 0.4822, 0.4465)` æ ‡å‡†åŒ–
3. **ä¸è°ƒç”¨ `zero_grad()`** â†’ æ¢¯åº¦ç´¯åŠ å¯¼è‡´è®­ç»ƒå¤±è´¥
4. **å¿˜è®°åˆ‡æ¢ `train()`/`eval()`** â†’ BatchNorm ç”¨é”™æ¨¡å¼
5. **æœªæŒ‡å®š `download=False`** â†’ ä¼šå°è¯•ä¸‹è½½æ•°æ®ï¼ˆå¤±è´¥ï¼‰

---

## âœ… ä½ å°†æŒæ¡çš„æ ¸å¿ƒæŠ€èƒ½

1. ä½¿ç”¨ `torchvision` åŠ è½½è§†è§‰æ•°æ®é›†
2. æ„å»º CNN æ¨¡å‹ï¼ˆå·ç§¯å±‚ â†’ å…¨è¿æ¥å±‚ï¼‰
3. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆResNet/VGGï¼‰å¹¶ä¿®æ”¹
4. ç”¨ TensorBoard ç›‘æ§è®­ç»ƒè¿‡ç¨‹
5. æ­£ç¡®ä½¿ç”¨ `train()`/`eval()` å’Œ `no_grad()`

> ğŸ’¡ **ä¸‹ä¸€æ­¥**ï¼šå°è¯•æ›´æ¢æ¨¡å‹ï¼ˆä» SimpleCNN â†’ ResNet18ï¼‰ï¼Œè§‚å¯Ÿ TensorBoard ä¸­çš„ loss æ›²çº¿å˜åŒ–ï¼Œç†è§£**æ¨¡å‹å¤æ‚åº¦å¯¹è®­ç»ƒçš„å½±å“**ã€‚


è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼ä½ æåˆ°çš„ **â€œåƒå®˜ç½‘ Toronto ä¸€æ ·ç”¨ pickle å¯¼å…¥ CIFAR-10â€**ï¼Œå…¶å®æ­£æ˜¯ **CIFAR-10 å®˜æ–¹åŸå§‹æ•°æ®æ ¼å¼**ã€‚ä¸‹é¢æˆ‘æ¥è¯¦ç»†è§£é‡Šï¼š

---

### âœ… ä¸€ã€CIFAR-10 çš„ä¸¤ç§å¸¸è§æ ¼å¼

#### 1. **å®˜æ–¹åŸå§‹æ ¼å¼ï¼ˆToronto æ ¼å¼ï¼‰**
- ç”± [Alex Krizhevsky](https://www.cs.toronto.edu/~kriz/cifar.html) å‘å¸ƒ
- æ•°æ®ä»¥ **Python `pickle` æ–‡ä»¶** å­˜å‚¨ï¼ˆ`.pkl` æˆ– `.bin`ï¼‰
- æ¯ä¸ªæ–‡ä»¶åŒ…å«å­—å…¸ï¼š`{'data': ..., 'labels': ...}`
- **éœ€è¦æ‰‹åŠ¨ç”¨ `pickle` è¯»å–**

#### 2. **PyTorch `torchvision.datasets.CIFAR10` æ ¼å¼**
- PyTorch å°è£…å¥½çš„æ¥å£
- **å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† pickle æ–‡ä»¶**
- ä½ åªéœ€è°ƒç”¨ `CIFAR10(root=..., download=True)`ï¼Œå®ƒä¼šï¼š
  - ä¸‹è½½å®˜æ–¹ pickle æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
  - è‡ªåŠ¨è§£å‹å¹¶è§£æ
  - è¿”å› `PIL.Image` + `int label`

> ğŸ”‘ **å…³é”®ç»“è®º**ï¼š  
> **ä½ å®Œå…¨å¯ä»¥åƒ Toronto å®˜ç½‘é‚£æ ·ç”¨ `pickle` ç›´æ¥è¯»å–**ï¼Œä½† **`torchvision.datasets.CIFAR10` å·²ç»ä¸ºä½ åšäº†è¿™ä»¶äº‹**ï¼

---

### âœ… äºŒã€ä¸ºä»€ä¹ˆä½ â€œä¸èƒ½ç”¨ pickle åƒå®˜ç½‘ä¸€æ ·å¯¼å…¥â€ï¼Ÿ

å¾ˆå¯èƒ½æ˜¯å› ä¸º **ä½ çš„æ•°æ®ç›®å½•ç»“æ„ä¸å¯¹**ã€‚

#### ğŸ“‚ æ­£ç¡®çš„ Toronto æ ¼å¼ç›®å½•ç»“æ„åº”ä¸ºï¼š
```
train/cifar10/
â”œâ”€â”€ cifar-10-batches-py/
â”‚   â”œâ”€â”€ data_batch_1
â”‚   â”œâ”€â”€ data_batch_2
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ test_batch
â”‚   â””â”€â”€ batches.meta
```

> âš ï¸ æ³¨æ„ï¼š**å¿…é¡»æœ‰ä¸€ä¸ª `cifar-10-batches-py/` å­ç›®å½•**ï¼  
> è¿™æ˜¯å®˜æ–¹å‹ç¼©åŒ…è§£å‹åçš„æ ‡å‡†ç»“æ„ã€‚

#### âŒ å¦‚æœä½ åªæœ‰ï¼š
```
train/cifar10/
â”œâ”€â”€ data_batch_1
â”œâ”€â”€ test_batch
â””â”€â”€ ...
```
â†’ **ç¼ºå°‘ `cifar-10-batches-py/` ç›®å½•** â†’ `torchvision` ä¼šæŠ¥é”™ï¼

---

### âœ… ä¸‰ã€è§£å†³æ–¹æ¡ˆï¼šä¸¤ç§æ–¹å¼ä»»é€‰

---

#### âœ… æ–¹æ¡ˆ Aï¼š**è®© `torchvision` æ­£å¸¸å·¥ä½œï¼ˆæ¨èï¼‰**

1. **ç¡®ä¿ç›®å½•ç»“æ„æ­£ç¡®**ï¼š
   ```bash
   # ä½ çš„æ•°æ®åº”è¯¥åœ¨è¿™é‡Œï¼š
   ls train/cifar10/cifar-10-batches-py/
   # åº”çœ‹åˆ° data_batch_1, test_batch ç­‰
   ```

2. **ä»£ç ä¸­è®¾ç½® `download=False`**ï¼š
   ```python
   trainset = torchvision.datasets.CIFAR10(
       root='train/cifar10',  # æŒ‡å‘çˆ¶ç›®å½•ï¼
       train=True,
       download=False,       # ä¸ä¸‹è½½ï¼Œç”¨æœ¬åœ°æ•°æ®
       transform=transform
   )
   ```
   > ğŸ’¡ `root` æ˜¯ **åŒ…å« `cifar-10-batches-py/` çš„ç›®å½•**ï¼Œä¸æ˜¯ç›´æ¥æŒ‡å‘ batch æ–‡ä»¶ï¼

---

#### âœ… æ–¹æ¡ˆ Bï¼š**æ‰‹åŠ¨ç”¨ `pickle` è¯»å–ï¼ˆç†è§£åŸç†ï¼‰**

å¦‚æœä½ æƒ³çŸ¥é“ Toronto å®˜ç½‘æ˜¯æ€ä¹ˆåšçš„ï¼Œå¯ä»¥è¿™æ ·å†™ï¼š

```python
import pickle
import numpy as np
from PIL import Image

def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

# è¯»å–ä¸€ä¸ª batch
batch = unpickle('train/cifar10/cifar-10-batches-py/data_batch_1')

# æå–æ•°æ®
data = batch[b'data']        # shape: (10000, 3072)
labels = batch[b'labels']    # list of 10000 ints

# è½¬æ¢ä¸ºå›¾åƒ (32x32x3)
images = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # NHWC

# è½¬ä¸º PIL Imageï¼ˆæ‰èƒ½ç”¨ transformsï¼‰
pil_images = [Image.fromarray(img) for img in images]
```

> ğŸ” è¿™å°±æ˜¯ `torchvision.datasets.CIFAR10` å†…éƒ¨åšçš„äº‹æƒ…ï¼

---

### âœ… å››ã€éªŒè¯ä½ çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ

è¿è¡Œä»¥ä¸‹ä»£ç æ£€æŸ¥ï¼š

```python
import torchvision
from torchvision.datasets import CIFAR10

try:
    dataset = CIFAR10(root='train/cifar10', train=True, download=False)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} å¼ è®­ç»ƒå›¾åƒ")
    print(f"ç¬¬ä¸€å¼ å›¾ç±»å‹: {type(dataset[0][0])}")  # åº”è¯¥æ˜¯ <class 'PIL.Image.Image'>
except Exception as e:
    print(f"âŒ åŠ è½½å¤±è´¥: {e}")
```

å¦‚æœæŠ¥é”™ï¼š
- `FileNotFoundError` â†’ ç›®å½•ç»“æ„é”™è¯¯
- `EOFError` â†’ pickle æ–‡ä»¶æŸå
- `UnicodeDecodeError` â†’ ç¼–ç é—®é¢˜ï¼ˆéœ€åŠ  `encoding='bytes'`ï¼‰

---

### âœ… äº”ã€æ€»ç»“ï¼šä½ åº”è¯¥æ€ä¹ˆåšï¼Ÿ

| ä½ çš„æƒ…å†µ | æ¨èåšæ³• |
|--------|--------|
| **æƒ³å¿«é€Ÿè®­ç»ƒ** | âœ… ç”¨ `torchvision.datasets.CIFAR10` + æ­£ç¡®ç›®å½•ç»“æ„ |
| **æƒ³ç†è§£åº•å±‚åŸç†** | âœ… æ‰‹åŠ¨å†™ `unpickle` å‡½æ•°ï¼ˆå¦‚ä¸Šï¼‰ |
| **æ•°æ®ç›®å½•ä¸å¯¹** | ğŸ”§ æŠŠæ‰€æœ‰ batch æ–‡ä»¶æ”¾è¿› `cifar-10-batches-py/` å­ç›®å½• |

> ğŸŒŸ **æœ€ä½³å®è·µ**ï¼š  
> **ä½¿ç”¨ `torchvision.datasets.CIFAR10`**ï¼Œå› ä¸ºå®ƒï¼š
> - è‡ªåŠ¨å¤„ç† pickle è§£æ
> - æ”¯æŒ `transforms`
> - å…¼å®¹ DataLoader
> - é¿å…æ‰‹åŠ¨å†…å­˜ç®¡ç†

---

### ğŸ”§ é™„ï¼šå¦‚ä½•ä¿®å¤ç›®å½•ç»“æ„ï¼Ÿ

å¦‚æœä½ çš„æ•°æ®ç›´æ¥æ”¾åœ¨ `train/cifar10/` ä¸‹ï¼ˆæ²¡æœ‰å­ç›®å½•ï¼‰ï¼Œæ‰§è¡Œï¼š

```bash
mkdir -p train/cifar10/cifar-10-batches-py
mv train/cifar10/data_batch_* train/cifar10/test_batch train/cifar10/batches.meta train/cifar10/cifar-10-batches-py/
```

ç„¶åä½ çš„ä»£ç å°±èƒ½æ­£å¸¸å·¥ä½œäº†ï¼

---

ç°åœ¨ä½ åº”è¯¥æ˜ç™½ï¼š**ä¸æ˜¯ä¸èƒ½ç”¨ pickleï¼Œè€Œæ˜¯ `torchvision` å·²ç»å¸®ä½ ç”¨äº†**ï¼Œä½ åªéœ€è¦æä¾›æ­£ç¡®çš„ç›®å½•ç»“æ„å³å¯ ğŸ˜Š

ğŸ”¥ æ ¸å¿ƒé”™è¯¯åˆ†æ
python

ç¼–è¾‘



# é”™è¯¯ä»£ç ï¼š
model = SimpleCNN.to(DEVICE)
é—®é¢˜ï¼š
SimpleCNN æ˜¯ä¸€ä¸ªç±»ï¼ˆclassï¼‰ï¼Œä¸æ˜¯å®ä¾‹ï¼ä½ ä¸èƒ½å¯¹ç±»è°ƒç”¨ .to()ã€‚
âœ… æ­£ç¡®åšæ³•ï¼šå…ˆåˆ›å»ºå®ä¾‹ï¼Œå†ç§»åŠ¨åˆ°è®¾å¤‡ã€‚
python

ç¼–è¾‘



model = SimpleCNN().to(DEVICE)  # â† æ³¨æ„æ‹¬å· () åˆ›å»ºå®ä¾‹
ğŸ’¡ è¿™å°±æ˜¯æŠ¥é”™ AttributeError: 'torch.device' object has no attribute '_apply' çš„åŸå›  â€”â€” Python æŠŠ DEVICE å½“æˆäº† self å‚æ•°ä¼ ç»™äº† to() æ–¹æ³•ã€‚

ğŸ“Œ å…³é”®çŸ¥è¯†ç‚¹æ€»ç»“
.to(DEVICE) å¿…é¡»ä½œç”¨äºæ¨¡å‹å®ä¾‹ï¼Œä¸æ˜¯ç±»
è®­ç»ƒ/æµ‹è¯•å˜æ¢è¦åˆ†å¼€ï¼šæµ‹è¯•é›†ä¸èƒ½åš RandomCrop/Flip
torch.flatten(x, 1) æ¯” x.view(x.size(0), -1) æ›´å®‰å…¨
TensorBoard æ—¥å¿—ä¸è¦æ¯æ­¥éƒ½å†™ï¼ˆä¼šå˜æ…¢ï¼‰ï¼Œå»ºè®®æ¯ N æ­¥æˆ–æ¯ epoch
å§‹ç»ˆä½¿ç”¨ model.train() / model.eval() åˆ‡æ¢æ¨¡å¼


è¿™æ˜¯ä¸€ä¸ª**éå¸¸æ ¸å¿ƒä¸”æ·±åˆ»çš„é—®é¢˜**ï¼Œæ¶‰åŠåˆ°æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­çš„**æ”¶æ•›åˆ¤æ–­ã€è¿‡æ‹Ÿåˆè¯†åˆ«å’Œæ€§èƒ½ç“¶é¢ˆåˆ†æ**ã€‚ä½ çš„ç›´è§‰ï¼ˆâ€œæµ‹è¯•å‡†ç¡®ç‡å˜åŒ–å°â€ï¼‰æ˜¯æ­£ç¡®çš„èµ·ç‚¹ï¼Œä½†**ä»…é è¿™ä¸€ç‚¹è¿œè¿œä¸å¤Ÿ**ã€‚

ä¸‹é¢æˆ‘å°†ç³»ç»Ÿæ€§åœ°å‘Šè¯‰ä½ ï¼š**å¦‚ä½•ç§‘å­¦åˆ¤æ–­ç½‘ç»œæ˜¯å¦è¾¾åˆ°å­¦ä¹ æé™ï¼Ÿ**

---

## âœ… ä¸€ã€ä»€ä¹ˆæ˜¯â€œå­¦ä¹ æé™â€ï¼Ÿ

> **å­¦ä¹ æé™ = æ¨¡å‹åœ¨å½“å‰æ¶æ„ã€æ•°æ®ã€ä¼˜åŒ–ç­–ç•¥ä¸‹æ‰€èƒ½è¾¾åˆ°çš„æœ€ä½³æ³›åŒ–æ€§èƒ½**

å®ƒä¸ç­‰äº 100% å‡†ç¡®ç‡ï¼CIFAR-10 çš„äººç±»æ°´å¹³çº¦ 94%ï¼ŒSOTA æ¨¡å‹å¯è¾¾ 96~97%ï¼Œç®€å• CNN å¯èƒ½åªæœ‰ 70~80%ã€‚

---

## ğŸ” äºŒã€åˆ¤æ–­å­¦ä¹ æé™çš„ **5 ä¸ªå…³é”®ä¿¡å·**ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰

### ğŸ“Œ 1. **æµ‹è¯•æŸå¤±ï¼ˆTest Lossï¼‰ä¸å†ä¸‹é™ï¼Œç”šè‡³å¼€å§‹ä¸Šå‡** â† **æœ€å¯é æŒ‡æ ‡ï¼**
- âœ… **ç†æƒ³æƒ…å†µ**ï¼šè®­ç»ƒ loss â†“ï¼Œæµ‹è¯• loss â†“ â†’ æ¨¡å‹åœ¨å­¦ä¹ 
- âš ï¸ **è¾¾åˆ°æé™**ï¼šè®­ç»ƒ loss ç»§ç»­ â†“ï¼Œä½†**æµ‹è¯• loss åœæ»æˆ–ä¸Šå‡** â†’ **è¿‡æ‹Ÿåˆå¼€å§‹**
- âŒ **ä¸¥é‡è¿‡æ‹Ÿåˆ**ï¼šè®­ç»ƒ loss â‰ˆ 0ï¼Œæµ‹è¯• loss å¾ˆé«˜

> ğŸ’¡ **ä¸ºä»€ä¹ˆçœ‹ loss è€Œä¸æ˜¯ accuracyï¼Ÿ**  
> Accuracy æ˜¯ç¦»æ•£æŒ‡æ ‡ï¼ˆ0/1ï¼‰ï¼Œå¯¹å¾®å°å˜åŒ–ä¸æ•æ„Ÿï¼›Loss æ˜¯è¿ç»­å€¼ï¼Œæ›´èƒ½åæ˜ æ¨¡å‹ç½®ä¿¡åº¦ã€‚

#### âœ… ç›‘æ§å»ºè®®ï¼š
```python
# åœ¨ TensorBoard ä¸­åŒæ—¶è®°å½•
writer.add_scalar('Loss/train', train_loss, epoch)
writer.add_scalar('Loss/test', test_loss, epoch)  # â† å…³é”®ï¼
```

---

### ğŸ“Œ 2. **æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracyï¼‰è¿ç»­å¤šä¸ª epoch å˜åŒ– < 0.1%**
- è¿ç»­ 5~10 ä¸ª epochï¼Œæµ‹è¯•å‡†ç¡®ç‡æ³¢åŠ¨åœ¨ Â±0.1% å†…
- ä¸”æ²¡æœ‰æ˜æ˜¾ä¸Šå‡è¶‹åŠ¿ï¼ˆå¯ç”¨æ»‘åŠ¨å¹³å‡åˆ¤æ–­ï¼‰

> âš ï¸ æ³¨æ„ï¼š**ä¸è¦åªçœ‹æœ€åå‡ ä¸ªç‚¹**ï¼å¯èƒ½åªæ˜¯æš‚æ—¶å¹³å°æœŸï¼Œåé¢è¿˜ä¼šæ¶¨ã€‚

#### âœ… å®è·µæŠ€å·§ï¼š
- è®¡ç®—æœ€è¿‘ 5 ä¸ª epoch çš„å‡†ç¡®ç‡æ ‡å‡†å·®
- å¦‚æœ `std < 0.001`ï¼ˆå³ 0.1%ï¼‰ï¼Œå¯è®¤ä¸ºæ”¶æ•›

---

### ğŸ“Œ 3. **è®­ç»ƒæŸå¤±ä¸æµ‹è¯•æŸå¤±çš„ gap ç¨³å®šæˆ–æ‰©å¤§**
- åˆå§‹é˜¶æ®µï¼štrain loss > test lossï¼ˆæ­£å¸¸ï¼‰
- ä¸­æœŸï¼šä¸¤è€…åŒæ­¥ä¸‹é™
- **è¾¾åˆ°æé™æ—¶**ï¼štrain loss ç»§ç»­é™ï¼Œtest loss ä¸åŠ¨ â†’ **gap æ‰©å¤§**

> ğŸ“Š åœ¨ TensorBoard ä¸­ç”»ä¸¤æ¡ loss æ›²çº¿ï¼Œè§‚å¯Ÿ gapï¼

---

### ğŸ“Œ 4. **æ¢¯åº¦èŒƒæ•°ï¼ˆGradient Normï¼‰è¶‹è¿‘äº 0**
- å½“æ¨¡å‹æ¥è¿‘æå°å€¼ç‚¹æ—¶ï¼Œæ¢¯åº¦ä¼šå˜å¾—éå¸¸å°
- å¯ç›‘æ§ `torch.norm(param.grad)` çš„å¹³å‡å€¼

```python
total_norm = 0
for p in model.parameters():
    if p.grad is not None:
        total_norm += p.grad.data.norm(2).item()
writer.add_scalar('GradNorm', total_norm, step)
```
- å¦‚æœ `GradNorm < 1e-5` ä¸”ç¨³å®š â†’ å¯èƒ½å·²æ”¶æ•›

---

### ğŸ“Œ 5. **éªŒè¯é›†æ€§èƒ½é•¿æ—¶é—´æ— æ³•è¶…è¶Š SOTA æˆ–ç†è®ºä¸Šé™**
- ä¾‹å¦‚ï¼šCIFAR-10 ä¸Š ResNet-18 çš„å…¸å‹å‡†ç¡®ç‡æ˜¯ ~94%
- å¦‚æœä½ çš„ ResNet-18 è®­äº† 200 epoch è¿˜åªæœ‰ 85%ï¼Œå¯èƒ½æ˜¯ï¼š
  - æ•°æ®é¢„å¤„ç†é”™è¯¯
  - å­¦ä¹ ç‡ä¸åˆé€‚
  - æ¨¡å‹å®ç° bug
  - **è€Œéâ€œå·²è¾¾æé™â€**

> âœ… **å…ˆç¡®è®¤ baseline æ˜¯å¦åˆç†ï¼**

---

## ğŸš« ä¸‰ã€å¸¸è§è¯¯åˆ¤ï¼ˆä½ å¿…é¡»é¿å…ï¼ï¼‰

| è¯¯åˆ¤ | çœŸç›¸ |
|------|------|
| â€œè®­ç»ƒ loss å¾ˆä½ = å­¦å¾—å¥½â€ | å¯èƒ½ä¸¥é‡è¿‡æ‹Ÿåˆï¼å¿…é¡»çœ‹ test loss |
| â€œå‡†ç¡®ç‡ä¸‰å¤©æ²¡æ¶¨ = æ”¶æ•›äº†â€ | å¯èƒ½æ˜¯å­¦ä¹ ç‡å¤ªå¤§ï¼Œå¡åœ¨å±€éƒ¨æœ€ä¼˜ |
| â€œloss éœ‡è¡ = ä¸è¡Œäº†â€ | å¯èƒ½æ˜¯ batch size å¤ªå°ï¼Œæ­£å¸¸ç°è±¡ |

---

## ğŸ› ï¸ å››ã€å®ç”¨å†³ç­–æµç¨‹å›¾

```mermaid
graph TD
    A[è®­ç»ƒè¿›è¡Œä¸­] --> B{Test Loss æ˜¯å¦æŒç»­ä¸‹é™?}
    B -- æ˜¯ --> C[ç»§ç»­è®­ç»ƒ]
    B -- å¦ --> D{Test Loss æ˜¯å¦ä¸Šå‡?}
    D -- æ˜¯ --> E[å·²è¿‡æ‹Ÿåˆ! åœæ­¢è®­ç»ƒ]
    D -- å¦ --> F{Test Acc è¿ç»­5 epoch å˜åŒ–<0.1%?}
    F -- å¦ --> C
    F -- æ˜¯ --> G{Train-Test Loss Gap æ˜¯å¦ç¨³å®š?}
    G -- æ˜¯ --> H[å¯èƒ½å·²è¾¾å­¦ä¹ æé™]
    G -- å¦ --> I[å¯èƒ½æ¬ æ‹Ÿåˆ/ä¼˜åŒ–é—®é¢˜]
```

---

## ğŸ”§ äº”ã€è¿›é˜¶æŠ€å·§ï¼šä¸»åŠ¨æ¢æµ‹æé™

### 1. **å­¦ä¹ ç‡æ‰«æï¼ˆLR Finderï¼‰**
- ç”¨å°èŒƒå›´æ•°æ®ï¼Œä» `1e-6` åˆ° `1` æ‰«æ lr
- æ‰¾åˆ° loss ä¸‹é™æœ€å¿«çš„ lr â†’ å¯èƒ½çªç ´å½“å‰ç“¶é¢ˆ

### 2. **æ—©åœï¼ˆEarly Stoppingï¼‰**
```python
from torch.optim.lr_scheduler import ReduceLROnPlateau

scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)
# å½“ test acc 5 epoch ä¸æå‡ï¼Œlr å‡åŠ
```

### 3. **æ¨¡å‹å®¹é‡æ£€æŸ¥**
- å¦‚æœç®€å•æ¨¡å‹ï¼ˆå¦‚ä½ çš„ SimpleCNNï¼‰å¾ˆå¿«é¥±å’Œï¼ˆ~75%ï¼‰
- å°è¯•æ›´å¤§æ¨¡å‹ï¼ˆResNet18ï¼‰â†’ å¦‚æœè¿˜èƒ½æå‡ï¼Œè¯´æ˜åŸæ¨¡å‹ capacity ä¸è¶³

---

## ğŸ“Š å…­ã€CIFAR-10 å…¸å‹æ€§èƒ½å‚è€ƒ

| æ¨¡å‹ | åˆç†æµ‹è¯•å‡†ç¡®ç‡ | è¾¾åˆ°æé™çš„ epoch |
|------|----------------|------------------|
| SimpleCNNï¼ˆä½ çš„ç»“æ„ï¼‰ | 70% ~ 78% | 30~50 epoch |
| ResNet-18 | 92% ~ 94% | 100~200 epoch |
| VGG-11 | 90% ~ 92% | 80~150 epoch |

> ğŸ’¡ å¦‚æœä½ çš„ SimpleCNN åœ¨ 50 epoch å test acc åœåœ¨ 75% ä¸åŠ¨ï¼Œ**å¾ˆå¯èƒ½å·²è¾¾è¯¥æ¨¡å‹çš„å­¦ä¹ æé™**ã€‚

---

## âœ… æ€»ç»“ï¼šä½•æ—¶åœæ­¢è®­ç»ƒï¼Ÿ

| æ¡ä»¶ | è¡ŒåŠ¨ |
|------|------|
| âœ… **Test Loss è¿ç»­ 5 epoch ä¸é™ + Test Acc æ³¢åŠ¨ < 0.1%** | å¯åœæ­¢ |
| âœ… **Test Loss å¼€å§‹ä¸Šå‡** | ç«‹å³åœæ­¢ï¼ˆè¿‡æ‹Ÿåˆï¼‰ |
| âŒ ä»… Train Loss å¾ˆä½ | ç»§ç»­è®­ç»ƒ |
| âŒ Test Acc å•æ¬¡ epoch ä¸æ¶¨ | ç»§ç»­è§‚å¯Ÿ |

> ğŸŒŸ **ç»ˆæå»ºè®®**ï¼š  
> **æ°¸è¿œä»¥ Test Loss ä¸ºä¸»è¦æŒ‡æ ‡ï¼ŒTest Accuracy ä¸ºè¾…åŠ©ï¼Œä¸¤è€…ç»“åˆåˆ¤æ–­**ã€‚  
> å¹¶åœ¨ TensorBoard ä¸­**åŒæ—¶ç›‘æ§ train/test çš„ loss å’Œ accuracy**ï¼

è¿™æ ·ä½ å°±èƒ½ç§‘å­¦åœ°åˆ¤æ–­ï¼šåˆ°åº•æ˜¯â€œå­¦ä¸åŠ¨äº†â€ï¼Œè¿˜æ˜¯â€œè¿˜èƒ½å†æŠ¢æ•‘ä¸€ä¸‹â€ ğŸ˜Š